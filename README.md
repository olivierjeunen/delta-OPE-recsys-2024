# Δ-OPE: Off-Policy Estimation with Pairs of Policies
Source code accompanying our paper "Δ-OPE: Off-Policy Estimation with Pairs of Policies" published at RecSys 2024.

### Discrete action spaces

Run the notebook Delta_Experiments_synthetic.ipynb

### Continuous action spaces

Run the notebook Delta_Experiments_synthetic_continuous.ipynb

## Acknowledgements
We build on source code provided for the RecSys 2024 paper "Optimal Baseline Corrections for Off-Policy Contextual Bandits" by Shashank Gupta, Olivier Jeunen, Harrie Oosterhuis and Maarten de Rijke.
Their repository can be found at: https://github.com/shashankg7/recsys2024_optimal_baseline

## Open-Bandit Readme
We thank Yuta Saito and collaborators for releasing the Open Bandit Pipeline. The experiments for our paper are based on the a modified OBP codebase. To view the original Readme file, please visit: https://github.com/st-tech/zr-obp.
